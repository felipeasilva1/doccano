{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mock/161704902/treino_1/Documentos/564.ner.csv', \n",
    "                 delimiter=';', na_values='NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMENTA</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXECUÇÃO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Token Tag\n",
       "0    EMENTA   O\n",
       "1         :   O\n",
       "2             O\n",
       "3  EXECUÇÃO   O\n",
       "4             O"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Token    0\n",
       "Tag      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B_Precedente', 'I_Precedente', 'B_Ref. Legislativa',\n",
       "       'I_Ref. Legislativa', 'B_Pessoa', 'I_Pessoa', 'B_Doutrinador',\n",
       "       'I_Doutrinador'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>HHCC</td>\n",
       "      <td>B_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>123.382</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>e</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>123.425</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>,</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Relatores</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>a</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Ministra</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Rosa</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Weber</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>e</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>o</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Ministro</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Dias</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Toffoli</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>,</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10365</th>\n",
       "      <td>Barroso</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10366</th>\n",
       "      <td></td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10369</th>\n",
       "      <td>Edson</td>\n",
       "      <td>B_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10370</th>\n",
       "      <td></td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>Fachin</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10372</th>\n",
       "      <td>.</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10385</th>\n",
       "      <td>Dr</td>\n",
       "      <td>B_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10386</th>\n",
       "      <td>.</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10387</th>\n",
       "      <td></td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10388</th>\n",
       "      <td>Paulo</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10389</th>\n",
       "      <td></td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10390</th>\n",
       "      <td>Gustavo</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10391</th>\n",
       "      <td></td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10392</th>\n",
       "      <td>Gonet</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10393</th>\n",
       "      <td></td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10394</th>\n",
       "      <td>\\n</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10395</th>\n",
       "      <td>\\n</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10396</th>\n",
       "      <td>Branco</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>.</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10401</th>\n",
       "      <td>Carmen</td>\n",
       "      <td>B_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10402</th>\n",
       "      <td></td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10403</th>\n",
       "      <td>Lilian</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10404</th>\n",
       "      <td></td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10405</th>\n",
       "      <td>Oliveira</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10406</th>\n",
       "      <td></td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10407</th>\n",
       "      <td>de</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10408</th>\n",
       "      <td></td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10409</th>\n",
       "      <td>Souza</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10410</th>\n",
       "      <td></td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10411</th>\n",
       "      <td>\\n</td>\n",
       "      <td>I_Pessoa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1072 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Token           Tag\n",
       "225         HHCC  B_Precedente\n",
       "226               I_Precedente\n",
       "227      123.382  I_Precedente\n",
       "228               I_Precedente\n",
       "229            e  I_Precedente\n",
       "230               I_Precedente\n",
       "231      123.425  I_Precedente\n",
       "232            ,  I_Precedente\n",
       "233               I_Precedente\n",
       "234    Relatores  I_Precedente\n",
       "235               I_Precedente\n",
       "236            a  I_Precedente\n",
       "237               I_Precedente\n",
       "238     Ministra  I_Precedente\n",
       "239               I_Precedente\n",
       "240         Rosa  I_Precedente\n",
       "241               I_Precedente\n",
       "242        Weber  I_Precedente\n",
       "243               I_Precedente\n",
       "244            e  I_Precedente\n",
       "245               I_Precedente\n",
       "246            o  I_Precedente\n",
       "247               I_Precedente\n",
       "248     Ministro  I_Precedente\n",
       "249               I_Precedente\n",
       "250         Dias  I_Precedente\n",
       "251               I_Precedente\n",
       "252      Toffoli  I_Precedente\n",
       "253            ,  I_Precedente\n",
       "254               I_Precedente\n",
       "...          ...           ...\n",
       "10365    Barroso      I_Pessoa\n",
       "10366                 I_Pessoa\n",
       "10369      Edson      B_Pessoa\n",
       "10370                 I_Pessoa\n",
       "10371     Fachin      I_Pessoa\n",
       "10372          .      I_Pessoa\n",
       "10385         Dr      B_Pessoa\n",
       "10386          .      I_Pessoa\n",
       "10387                 I_Pessoa\n",
       "10388      Paulo      I_Pessoa\n",
       "10389                 I_Pessoa\n",
       "10390    Gustavo      I_Pessoa\n",
       "10391                 I_Pessoa\n",
       "10392      Gonet      I_Pessoa\n",
       "10393                 I_Pessoa\n",
       "10394         \\n      I_Pessoa\n",
       "10395         \\n      I_Pessoa\n",
       "10396     Branco      I_Pessoa\n",
       "10397          .      I_Pessoa\n",
       "10401     Carmen      B_Pessoa\n",
       "10402                 I_Pessoa\n",
       "10403     Lilian      I_Pessoa\n",
       "10404                 I_Pessoa\n",
       "10405   Oliveira      I_Pessoa\n",
       "10406                 I_Pessoa\n",
       "10407         de      I_Pessoa\n",
       "10408                 I_Pessoa\n",
       "10409      Souza      I_Pessoa\n",
       "10410                 I_Pessoa\n",
       "10411         \\n      I_Pessoa\n",
       "\n",
       "[1072 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.query(\"Tag.str.contains('B_')\", engine='python')\n",
    "df.query(\"Tag not in 'O'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B_Doutrinador</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_Pessoa</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B_Precedente</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B_Ref. Legislativa</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I_Doutrinador</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I_Pessoa</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I_Precedente</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O</td>\n",
       "      <td>9348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Tag  Count\n",
       "0       B_Doutrinador      2\n",
       "1            B_Pessoa     19\n",
       "2        B_Precedente     20\n",
       "3  B_Ref. Legislativa     38\n",
       "4       I_Doutrinador    100\n",
       "5            I_Pessoa    121\n",
       "6        I_Precedente    370\n",
       "7  I_Ref. Legislativa    402\n",
       "8                   O   9348"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Tag').size().reset_index(name='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porção de tags que não são \"O\":  10.287907869481765 %\n"
     ]
    }
   ],
   "source": [
    "print('Porção de tags que não são \"O\": ',len(df[df['Tag']!='O'])/len(df) * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6981, 1263), (6981,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Tag', axis=1) # Define o conjunto X\n",
    "v = DictVectorizer(sparse=False) # Função que transforma listas de features em vetores\n",
    "X = v.fit_transform(X.to_dict('records')) #Aplica a função de vetorização no conjunto \n",
    "                                          #X que foi colocado no formato 'records' (informa o que preenche cada coluna \n",
    "                                          # da linha i)\n",
    "y = df.Tag.values # Define o conjunto y\n",
    "\n",
    "classes = np.unique(y) # Define quais serão as classes baseado nos valores únicos da coluna y\n",
    "classes = classes.tolist() # Tranforma as classes de array para lista\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=0) # Divide o conjunto em treino\n",
    "                                                                                            #e teste\n",
    "X_train.shape, y_train.shape # Formato dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B_Doutrinador',\n",
       " 'B_Pessoa',\n",
       " 'B_Precedente',\n",
       " 'B_Ref. Legislativa',\n",
       " 'I_Doutrinador',\n",
       " 'I_Pessoa',\n",
       " 'I_Precedente',\n",
       " 'I_Ref. Legislativa',\n",
       " 'O']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tagged = nltk.pos_tag(df['Token'])\n",
    "pos_tag = []\n",
    "\n",
    "for i in range(len(tagged)):\n",
    "    pos_tag.append(tagged[i][1])\n",
    "df['POS'] = pos_tag\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(doc, i):\n",
    "#     word = doc.iloc[i][0]\n",
    "#     postag = doc.iloc[i][1]\n",
    "    word = doc[i][0]\n",
    "    postag = doc[i][1]\n",
    "\n",
    "    # Common features for all words\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag\n",
    "    ]\n",
    "\n",
    "    # Features for words that are not\n",
    "    # at the beginning of a document\n",
    "    if i > 0:\n",
    "        word1 = doc[i-1][0]\n",
    "        postag1 = doc[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:word.isdigit=%s' % word1.isdigit(),\n",
    "            '-1:postag=' + postag1\n",
    "        ])\n",
    "    else:\n",
    "        # Indicate that it is the 'beginning of a document'\n",
    "        features.append('BOS')\n",
    "\n",
    "    # Features for words that are not\n",
    "    # at the end of a document\n",
    "    if i < len(doc)-1:\n",
    "        word1 = doc[i+1][0]\n",
    "        postag1 = doc[i+1][1]\n",
    "#         word1 = doc.iloc[i+1][0]\n",
    "#         postag1 = doc.iloc[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:word.isdigit=%s' % word1.isdigit(),\n",
    "            '+1:postag=' + postag1\n",
    "        ])\n",
    "    else:\n",
    "        # Indicate that it is the 'end of a document'\n",
    "        features.append('EOS')\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "def sent2labels(sent):\n",
    "#     return [label for token, label, postag in sent]\n",
    "    return [label for token, label in sent]\n",
    "def sent2tokens(sent):\n",
    "#     return [token for token, label, postag in sent]\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMENTA</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXECUÇÃO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Token Tag\n",
       "0    EMENTA   O\n",
       "1         :   O\n",
       "2             O\n",
       "3  EXECUÇÃO   O\n",
       "4             O"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sent2features(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Random Fields (CRFs) (necessita de POS)\n",
    "\n",
    "CRFs is often used for labeling or parsing of sequential data, such as natural language processing and CRFs find applications in POS Tagging, named entity recognition, among others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B_Doutrinador',\n",
       " 'B_Pessoa',\n",
       " 'B_Precedente',\n",
       " 'B_Ref. Legislativa',\n",
       " 'I_Doutrinador',\n",
       " 'I_Pessoa',\n",
       " 'I_Precedente',\n",
       " 'I_Ref. Legislativa']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo a tag 'O'\n",
    "new_classes = classes.copy()\n",
    "new_classes.pop()\n",
    "new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa as frases para criar contexto na aprendizagem\n",
    "\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "#         agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(), \n",
    "#                                                            s['POS'].values.tolist(), \n",
    "#                                                            s['Tag'].values.tolist())]\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s['Token'].values.tolist(),\n",
    "                                                     s['Tag'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('Token').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None\n",
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo as tags que aparecem\n",
    "l=[]\n",
    "for i in range(len(X_train_crf)):\n",
    "    k = X_train_crf[i][0]['postag']\n",
    "    l.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 747,\n",
       "         'I_Ref. Legislativa': 28,\n",
       "         'I_Precedente': 36,\n",
       "         'I_Doutrinador': 15,\n",
       "         'B_Ref. Legislativa': 3,\n",
       "         'I_Pessoa': 12,\n",
       "         'B_Doutrinador': 2,\n",
       "         'B_Precedente': 2,\n",
       "         'B_Pessoa': 1})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985324564608452"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    all_possible_transitions=True)\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=new_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     B_Doutrinador       0.00      0.00      0.00         0\n",
      "          B_Pessoa       0.91      1.00      0.95        10\n",
      "      B_Precedente       1.00      0.92      0.96        12\n",
      "B_Ref. Legislativa       1.00      1.00      1.00         3\n",
      "     I_Doutrinador       1.00      1.00      1.00        65\n",
      "          I_Pessoa       1.00      1.00      1.00        82\n",
      "      I_Precedente       1.00      1.00      1.00       234\n",
      "I_Ref. Legislativa       1.00      1.00      1.00       274\n",
      "\n",
      "         micro avg       1.00      1.00      1.00       680\n",
      "         macro avg       0.86      0.86      0.86       680\n",
      "      weighted avg       1.00      1.00      1.00       680\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaline/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaline/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(y_test, y_pred, labels = new_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "                                 all_possible_transitions=True, averaging=None,\n",
       "                                 c=None, c1=None, c2=None,\n",
       "                                 calibration_candidates=None,\n",
       "                                 calibration_eta=None,\n",
       "                                 calibration_max_trials=None,\n",
       "                                 calibration_rate=None,\n",
       "                                 calibration_samples=None, delta=None,\n",
       "                                 epsilon=None, error_sensitive=None,...\n",
       "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2da7cc5ba8>,\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f2da6458940>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False,\n",
       "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=['B_Doutrinador', 'B_Pessoa', 'B_Precedente', 'B_Ref. Legislativa', 'I_Doutrinador', 'I_Pessoa', 'I_Precedente', 'I_Ref. Legislativa']),\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=new_classes)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'c1': 0.496294136435744, 'c2': 0.014133375437348293}\n",
      "best CV score: 0.9956709956709957\n",
      "model size: 0.01M\n"
     ]
    }
   ],
   "source": [
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     B_Doutrinador       0.00      0.00      0.00         0\n",
      "          B_Pessoa       1.00      1.00      1.00        10\n",
      "      B_Precedente       1.00      1.00      1.00        12\n",
      "B_Ref. Legislativa       1.00      1.00      1.00         3\n",
      "     I_Doutrinador       1.00      1.00      1.00        65\n",
      "          I_Pessoa       1.00      1.00      1.00        82\n",
      "      I_Precedente       1.00      1.00      1.00       234\n",
      "I_Ref. Legislativa       1.00      1.00      1.00       274\n",
      "\n",
      "         micro avg       1.00      1.00      1.00       680\n",
      "         macro avg       0.88      0.88      0.88       680\n",
      "      weighted avg       1.00      1.00      1.00       680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=new_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('O', 'O'): 0.344466,\n",
       " ('I_Precedente', 'I_Precedente'): 0.379467,\n",
       " ('B_Ref. Legislativa', 'B_Ref. Legislativa'): 0.726671,\n",
       " ('B_Precedente', 'B_Precedente'): 1.072061}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.transition_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B_Precedente -> B_Precedente 1.072061\n",
      "B_Ref. Legislativa -> B_Ref. Legislativa 0.726671\n",
      "I_Precedente -> I_Precedente 0.379467\n",
      "O -> O 0.344466\n",
      "\n",
      "Top unlikely transitions:\n",
      "B_Precedente -> B_Precedente 1.072061\n",
      "B_Ref. Legislativa -> B_Ref. Legislativa 0.726671\n",
      "I_Precedente -> I_Precedente 0.379467\n",
      "O -> O 0.344466\n"
     ]
    }
   ],
   "source": [
    "# Transições mais prováveis\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%s -> %s %s\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of core Algorithms\n",
    "\n",
    "We will try some of the out-of-core algorithms that are designed to process data that is too large to fit into a single computer memory that support partial_fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.73, NNZs: 3, Bias: -1.000000, T: 6981, Avg. loss: 0.000430\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 4.58, NNZs: 18, Bias: -1.000000, T: 6981, Avg. loss: 0.002292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 4.58, NNZs: 15, Bias: -1.000000, T: 6981, Avg. loss: 0.000859\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 5.00, NNZs: 14, Bias: -1.000000, T: 6981, Avg. loss: 0.002292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 5.10, NNZs: 23, Bias: -2.000000, T: 6981, Avg. loss: 0.015041\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 8.83, NNZs: 50, Bias: -2.000000, T: 6981, Avg. loss: 0.016473\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 13.96, NNZs: 105, Bias: -3.000000, T: 6981, Avg. loss: 0.049993\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 13.08, NNZs: 91, Bias: -1.000000, T: 6981, Avg. loss: 0.061453\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.25, NNZs: 304, Bias: 1.000000, T: 6981, Avg. loss: 0.139665\n",
      "Total training time: 0.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=10, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron \n",
    "\n",
    "per = Perceptron(verbose=10) # ou per = Perceptron(verbose=10, n_jobs=-1, max_iter=5)\n",
    "per.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B_Doutrinador',\n",
       " 'B_Pessoa',\n",
       " 'B_Precedente',\n",
       " 'B_Ref. Legislativa',\n",
       " 'I_Doutrinador',\n",
       " 'I_Pessoa',\n",
       " 'I_Precedente',\n",
       " 'I_Ref. Legislativa']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo a tag 'O'\n",
    "new_classes = classes.copy()\n",
    "new_classes.pop()\n",
    "new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     B_Doutrinador       0.00      0.00      0.00         0\n",
      "          B_Pessoa       0.33      0.17      0.22         6\n",
      "      B_Precedente       0.40      1.00      0.57         2\n",
      "B_Ref. Legislativa       0.69      0.69      0.69        16\n",
      "     I_Doutrinador       0.00      0.00      0.00        41\n",
      "          I_Pessoa       0.00      0.00      0.00        43\n",
      "      I_Precedente       0.93      0.10      0.18       130\n",
      "I_Ref. Legislativa       0.62      0.20      0.30       123\n",
      "\n",
      "         micro avg       0.56      0.14      0.23       361\n",
      "         macro avg       0.37      0.27      0.24       361\n",
      "      weighted avg       0.58      0.14      0.20       361\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaline/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaline/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=per.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     B_Doutrinador       0.00      0.00      0.00         0\n",
      "          B_Pessoa       0.00      0.00      0.00         6\n",
      "      B_Precedente       1.00      1.00      1.00         2\n",
      "B_Ref. Legislativa       0.69      0.69      0.69        16\n",
      "     I_Doutrinador       0.05      0.12      0.07        41\n",
      "          I_Pessoa       0.20      0.02      0.04        43\n",
      "      I_Precedente       0.95      0.15      0.26       130\n",
      "I_Ref. Legislativa       0.65      0.11      0.18       123\n",
      "\n",
      "         micro avg       0.33      0.14      0.20       361\n",
      "         macro avg       0.44      0.26      0.28       361\n",
      "      weighted avg       0.63      0.14      0.21       361\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaline/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaline/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Classificador Linear com Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.partial_fit(X_train, y_train, classes)\n",
    "\n",
    "print(classification_report(y_pred=sgd.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     B_Doutrinador       0.00      0.00      0.00         0\n",
      "          B_Pessoa       0.33      0.17      0.22         6\n",
      "      B_Precedente       0.67      1.00      0.80         2\n",
      "B_Ref. Legislativa       0.69      0.69      0.69        16\n",
      "     I_Doutrinador       1.00      0.02      0.05        41\n",
      "          I_Pessoa       0.33      0.05      0.08        43\n",
      "      I_Precedente       0.83      0.22      0.35       130\n",
      "I_Ref. Legislativa       0.74      0.19      0.30       123\n",
      "\n",
      "         micro avg       0.73      0.19      0.30       361\n",
      "         macro avg       0.57      0.29      0.31       361\n",
      "      weighted avg       0.74      0.19      0.28       361\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaline/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kaline/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes classifier for multinomial models\n",
    "\n",
    "nb = MultinomialNB(alpha=0.01)\n",
    "nb.partial_fit(X_train, y_train, classes)\n",
    "\n",
    "print(classification_report(y_pred=nb.predict(X_test), y_true=y_test, labels = new_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
