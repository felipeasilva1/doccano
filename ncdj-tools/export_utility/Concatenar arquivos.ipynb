{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prioridades:\n",
    "+ Parâmetros utilizados no classificador.\n",
    "\n",
    "+ Analisar o formato dos dados que tem maior acerto e menor acerto tambem.\n",
    "\n",
    "+ Visualização: Separar o conjunto de test em 2 ou 3 arquivos e visualizar o que o modelo classificou e o que os anotadores classificaram (separar por id do anotador).\n",
    "\n",
    "+ Incluir POS tagging.\n",
    "\n",
    "+ Tranformar o dado $x_i$ em um $x'_i$ que incorpora os 2 últimos e próximos tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "os.chdir(\"mock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*/**/***/****.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'161704902/[PRATICA_ETAPA_1]/Documentos/20180510_Rcl_22328_314302526.ner.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_filenames[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cria uma tag de inicio e fim de arquivo em cada arquivo antes de apendar todos os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for all_files in all_filenames:\n",
    "    df = pd.read_csv(all_files,delimiter=';', na_values='NaN')\n",
    "    df['Tag'].iloc[0] , df['Tag'].iloc[-1] = ['INICIO_ARQ', 'FIM_ARQ']\n",
    "    frames.append(df)\n",
    "    \n",
    "combined_csv = pd.concat(frames)\n",
    "combined_csv.to_csv( \"combined_csv.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas dos arquivos concatenados: 967910\n"
     ]
    }
   ],
   "source": [
    "combined_csv.head() , combined_csv.tail()\n",
    "print(\"Número de linhas dos arquivos concatenados:\", len(combined_csv['Tag']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>967900</th>\n",
       "      <td>Chefe</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967901</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967902</th>\n",
       "      <td>do</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967903</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967904</th>\n",
       "      <td>Plenário</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967905</th>\n",
       "      <td>\\n</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967906</th>\n",
       "      <td>id</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967907</th>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967908</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967909</th>\n",
       "      <td>20141203_ADI_4350_285683668</td>\n",
       "      <td>FIM_ARQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Token      Tag\n",
       "967900                        Chefe        O\n",
       "967901                                     O\n",
       "967902                           do        O\n",
       "967903                                     O\n",
       "967904                     Plenário        O\n",
       "967905                           \\n        O\n",
       "967906                           id        O\n",
       "967907                            :        O\n",
       "967908                                     O\n",
       "967909  20141203_ADI_4350_285683668  FIM_ARQ"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontra parágrafo duplo no arquivo. Uma opção de separar por sentenças."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padrões(sentenças) encontrados: 9708\n"
     ]
    }
   ],
   "source": [
    "a_df = combined_csv #Simplifica o nome do arquivo \n",
    "starts = a_df[a_df['Token']=='\\n'].index & a_df[a_df['Token'].shift(-1)=='\\n'].index #Identifica os paragrafos duplos\n",
    "print(u'Padrões(sentenças) encontrados:', len(starts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>967898</th>\n",
       "      <td>Assessora</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967899</th>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967900</th>\n",
       "      <td>Chefe</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967901</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967902</th>\n",
       "      <td>do</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967903</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967904</th>\n",
       "      <td>Plenário</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967905</th>\n",
       "      <td>\\n</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967906</th>\n",
       "      <td>id</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967907</th>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967908</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967909</th>\n",
       "      <td>20141203_ADI_4350_285683668</td>\n",
       "      <td>FIM_ARQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Token      Tag\n",
       "967898                    Assessora        O\n",
       "967899                            -        O\n",
       "967900                        Chefe        O\n",
       "967901                                     O\n",
       "967902                           do        O\n",
       "967903                                     O\n",
       "967904                     Plenário        O\n",
       "967905                           \\n        O\n",
       "967906                           id        O\n",
       "967907                            :        O\n",
       "967908                                     O\n",
       "967909  20141203_ADI_4350_285683668  FIM_ARQ"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv.iloc[:starts[0]+2] # Primeira sentença\n",
    "combined_csv.iloc[starts[-1]+2:] # Última sentença"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tempo', '00:05:35')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "combined_csv['Sentence #'] = 'Sentence'\n",
    "\n",
    "combined_csv['Sentence #'][:starts[0]+2] = 'Sentence %d'%(1) # Primeira sentença\n",
    "combined_csv['Sentence #'][starts[-1]+2:] = 'Sentence %d'%(len(starts)+1) # Última sentença\n",
    "\n",
    "for i in range(1,len(starts)):\n",
    "    combined_csv['Sentence #'][starts[i-1]+2:starts[i]+2] = 'Sentence %d'%(i+1) \n",
    "combined_csv.head(), combined_csv.tail()\n",
    "end = time.time()\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "'tempo',time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9709"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_csv['Sentence #'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Sentence #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ementa</td>\n",
       "      <td>INICIO_ARQ</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acórdão</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token         Tag  Sentence #\n",
       "0   Ementa  INICIO_ARQ  Sentence 1\n",
       "1                    O  Sentence 1\n",
       "2        e           O  Sentence 1\n",
       "3                    O  Sentence 1\n",
       "4  Acórdão           O  Sentence 1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((648499, 36129), (648499,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = combined_csv.drop('Tag', axis=1) # Define o conjunto X\n",
    "v = DictVectorizer(sparse=True) # Função que transforma listas de features em vetores\n",
    "X = v.fit_transform(X.to_dict('records')) #Aplica a função de vetorização no conjunto \n",
    "                                          #X que foi colocado no formato 'records' (informa o que preenche cada coluna \n",
    "                                          # da linha i)\n",
    "y = combined_csv.Tag.values # Define o conjunto y\n",
    "\n",
    "classes = np.unique(y) # Define quais serão as classes baseado nos valores únicos da coluna y\n",
    "classes = classes.tolist() # Tranforma as classes de array para lista\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=0) # Divide o conjunto em treino\n",
    "                                                                                            #e teste\n",
    "X_train.shape, y_train.shape # Formato dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B_Doutrina',\n",
       " 'B_Doutrinador',\n",
       " 'B_Pessoa',\n",
       " 'B_Precedente',\n",
       " 'B_Ref. Legislativa',\n",
       " 'FIM_ARQ',\n",
       " 'INICIO_ARQ',\n",
       " 'I_Doutrina',\n",
       " 'I_Doutrinador',\n",
       " 'I_Pessoa',\n",
       " 'I_Precedente',\n",
       " 'I_Ref. Legislativa']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo a tag 'O'\n",
    "new_classes = classes.copy()\n",
    "new_classes.pop()\n",
    "new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa as frases para criar contexto na aprendizagem\n",
    "\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s['Token'].values.tolist(),\n",
    "                                                     s['Tag'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('Sentence #').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "#     postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "#         'postag': postag,\n",
    "#         'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "#         postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "#             '-1:postag': postag1,\n",
    "#             '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "#         print(i,type(word1),word1)\n",
    "#         postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "#             '+1:postag': postag1,\n",
    "#             '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv['Token'] = combined_csv['Token'].astype('str')\n",
    "getter = SentenceGetter(combined_csv)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 42s, sys: 344 ms, total: 1min 42s\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8184949279966993"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', #Gradient Descent\n",
    "    c1=0.1, # coefficient for L1 penalty\n",
    "    c2=0.1, # coefficient for L2 penalty\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True) # whether to include transitions that are possible, but not observed\n",
    "\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=new_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        B_Doutrina      0.772     0.616     0.685        99\n",
      "     B_Doutrinador      0.696     0.448     0.545        87\n",
      "          B_Pessoa      0.698     0.636     0.665       807\n",
      "      B_Precedente      0.848     0.750     0.796       913\n",
      "B_Ref. Legislativa      0.817     0.715     0.763       892\n",
      "           FIM_ARQ      1.000     0.712     0.832        59\n",
      "        INICIO_ARQ      1.000     0.724     0.840        58\n",
      "        I_Doutrina      0.758     0.812     0.784      4225\n",
      "     I_Doutrinador      0.771     0.647     0.703      3565\n",
      "          I_Pessoa      0.839     0.763     0.799      4701\n",
      "      I_Precedente      0.881     0.836     0.858     13490\n",
      "I_Ref. Legislativa      0.869     0.827     0.847     12040\n",
      "\n",
      "         micro avg      0.844     0.796     0.819     40936\n",
      "         macro avg      0.829     0.707     0.760     40936\n",
      "      weighted avg      0.844     0.796     0.818     40936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(y_test, y_pred, labels = new_classes, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(y_test)):\n",
    "    df = pd.DataFrame(zip(X_train[i], y_test[i], y_pred[i]))\n",
    "    result.append(df)\n",
    "    \n",
    "result = pd.concat(result)\n",
    "result.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_teste</th>\n",
       "      <th>y_teste</th>\n",
       "      <th>y_Previsto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bias': 1.0, 'word.lower()': 'comentando', 'w...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bias': 1.0, 'word.lower()': 'o', 'word[-3:]'...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bias': 1.0, 'word.lower()': 'art', 'word[-3:...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             X_teste y_teste y_Previsto\n",
       "0  {'bias': 1.0, 'word.lower()': 'comentando', 'w...       O          O\n",
       "1  {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...       O          O\n",
       "2  {'bias': 1.0, 'word.lower()': 'o', 'word[-3:]'...       O          O\n",
       "3  {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...       O          O\n",
       "4  {'bias': 1.0, 'word.lower()': 'art', 'word[-3:...       O          O"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns = ['X_teste','y_teste', 'y_Previsto']\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         {'bias': 1.0, 'word.lower()': 'comentando', 'w...\n",
       "1         {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "2         {'bias': 1.0, 'word.lower()': 'o', 'word[-3:]'...\n",
       "3         {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "4         {'bias': 1.0, 'word.lower()': 'art', 'word[-3:...\n",
       "5         {'bias': 1.0, 'word.lower()': '.', 'word[-3:]'...\n",
       "6         {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "7         {'bias': 1.0, 'word.lower()': '320', 'word[-3:...\n",
       "8         {'bias': 1.0, 'word.lower()': ',', 'word[-3:]'...\n",
       "9         {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "10        {'bias': 1.0, 'word.lower()': 'ii', 'word[-3:]...\n",
       "11        {'bias': 1.0, 'word.lower()': ',', 'word[-3:]'...\n",
       "12        {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "13        {'bias': 1.0, 'word.lower()': 'do', 'word[-3:]...\n",
       "14        {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "15        {'bias': 1.0, 'word.lower()': 'cpc', 'word[-3:...\n",
       "16        {'bias': 1.0, 'word.lower()': ',', 'word[-3:]'...\n",
       "17        {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "18        {'bias': 1.0, 'word.lower()': 'que', 'word[-3:...\n",
       "19        {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "20        {'bias': 1.0, 'word.lower()': 'recusa', 'word[...\n",
       "21        {'bias': 1.0, 'word.lower()': 'na', 'word[-3:]...\n",
       "22        {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "23        {'bias': 1.0, 'word.lower()': 'doutrina', 'wor...\n",
       "24        {'bias': 1.0, 'word.lower()': ',', 'word[-3:]'...\n",
       "25        {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "26        {'bias': 1.0, 'word.lower()': 'ricardo', 'word...\n",
       "27        {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "28        {'bias': 1.0, 'word.lower()': 'bechara', 'word...\n",
       "29        {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "                                ...                        \n",
       "164506    {'bias': 1.0, 'word.lower()': 'relator', 'word...\n",
       "164507    {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "164508    {'bias': 1.0, 'word.lower()': '\n",
       "', 'word[-3:]'...\n",
       "164509    {'bias': 1.0, 'word.lower()': '\n",
       "', 'word[-3:]'...\n",
       "164510    {'bias': 1.0, 'word.lower()': 'majoro', 'word[...\n",
       "164511    {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "164512    {'bias': 1.0, 'word.lower()': ',', 'word[-3:]'...\n",
       "164513    {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "164514    {'bias': 1.0, 'word.lower()': 'ainda', 'word[-...\n",
       "164515    {'bias': 1.0, 'word.lower()': ',', 'word[-3:]'...\n",
       "164516    {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "164517    {'bias': 1.0, 'word.lower()': 'em', 'word[-3:]...\n",
       "164518    {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "164519    {'bias': 1.0, 'word.lower()': '10%', 'word[-3:...\n",
       "164520    {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "164521    {'bias': 1.0, 'word.lower()': '(', 'word[-3:]'...\n",
       "164522    {'bias': 1.0, 'word.lower()': 'recurso', 'word...\n",
       "164523    {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "164524    {'bias': 1.0, 'word.lower()': 'extraordinário'...\n",
       "164525    {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "164526    {'bias': 1.0, 'word.lower()': '434.251', 'word...\n",
       "164527    {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "164528    {'bias': 1.0, 'word.lower()': 'rio', 'word[-3:...\n",
       "164529    {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "164530    {'bias': 1.0, 'word.lower()': 'de', 'word[-3:]...\n",
       "164531    {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "164532    {'bias': 1.0, 'word.lower()': 'janeiro', 'word...\n",
       "164533    {'bias': 1.0, 'word.lower()': ' ', 'word[-3:]'...\n",
       "164534    {'bias': 1.0, 'word.lower()': '\n",
       "', 'word[-3:]'...\n",
       "164535    {'bias': 1.0, 'word.lower()': '\n",
       "', 'word[-3:]'...\n",
       "Name: X_teste, Length: 164536, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0]['word.lower()'], y_train[0][0]\n",
    "result.X_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporção de erros: 0.03768780084601546\n"
     ]
    }
   ],
   "source": [
    "print('Proporção de erros:',result[result.y_teste != result.y_Previsto].shape[0] / result.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-f31b33bab4d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Top likely transitions:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint_transitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransition_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTop unlikely transitions:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn_crfsuite/estimator.py\u001b[0m in \u001b[0;36mtransition_features_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \"\"\"\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn_crfsuite/estimator.py\u001b[0m in \u001b[0;36m_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_cached\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_cached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagger_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.Tagger.info\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.Tagger.info\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pycrfsuite/_dumpparser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'parse_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_FILEHEADER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pycrfsuite/_dumpparser.py\u001b[0m in \u001b[0;36mparse_STATE_FEATURES\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_STATE_FEATURES\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\(\\d+\\) (.+) --> (.+): ([+-]?\\d+\\.\\d+)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "# Let’s check what classifier learned\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RECLAMAÇÃO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22.328</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RIO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DE</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>JANEIRO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\\n</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\\n</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token Tag\n",
       "14  RECLAMAÇÃO   O\n",
       "15               O\n",
       "16      22.328   O\n",
       "17               O\n",
       "18         RIO   O\n",
       "19               O\n",
       "20          DE   O\n",
       "21               O\n",
       "22     JANEIRO   O\n",
       "23               O\n",
       "24          \\n   O\n",
       "25          \\n   O"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "combined_csv.iloc[starts[i-1]+2:starts[i]+2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
