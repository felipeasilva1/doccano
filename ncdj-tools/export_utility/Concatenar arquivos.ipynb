{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prioridades:\n",
    "+ Parâmetros utilizados no classificador.\n",
    "\n",
    "+ Analisar o formato dos dados que tem maior acerto e menor acerto tambem.\n",
    "  \n",
    "+ Visualização: Separar o conjunto de test em 2 ou 3 arquivos e visualizar o que o modelo classificou e o que os anotadores classificaram (separar por id do anotador).\n",
    "\n",
    "+ Incluir POS tagging.\n",
    "\n",
    "+ Tranformar o dado $x_i$ em um $x'_i$ que incorpora os 2 últimos e próximos tokens.\n",
    "\n",
    "# Detalhes na predição\n",
    "\n",
    "+ B_ em espaço em branco\n",
    "\n",
    "+ Remover linhas com '\\n' seguidos\n",
    "\n",
    "+ Para criar um contexto no erro imprimir 10 palavras antes e depois de dois erros.\n",
    "\n",
    "+ REGEX:\n",
    "    + Garantir letra e números onde tamanho for maior que 1.\n",
    "    + Passar múltiplos símbolos para outra linha. Exemplo:  §3º -->  § \\n 3 \\n º\n",
    "    + Remover pontuação de centenas dos números. Exemplo: 12.200 --> 12200\n",
    "\n",
    "# Instruções para os anotadores:\n",
    "\n",
    "+ Atentar à marcação de tags que envolve espaço \n",
    "\n",
    "+ Atentar para não incluir espaço no início da Tag\n",
    "\n",
    "# Organização do diretório: \n",
    "\n",
    "+ Manter toda a análise em somente um diretório\n",
    "\n",
    "+ Formato do diretório com os datasets: /resources/dataset/\n",
    "\n",
    "+ Notebooks:\n",
    "    + '01 - ProcessamentodoDataset.ipynb'\n",
    "        + Gerar 'treino.csv' e teste.csv' para processamento\n",
    "    + '02 - [CRF].ipynb' - Criando o modelo\n",
    "        + Gerar modelo (xxx.model)\n",
    "        + Métricas\n",
    "    + '03 - Metricas.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter\n",
    "\n",
    "os.chdir(\"mock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*/**/***/****.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'161704902/[PRATICA_ETAPA_1]/Documentos/20180510_Rcl_22328_314302526.ner.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_filenames[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cria uma tag de inicio e fim de arquivo em cada arquivo antes de apendar todos os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for all_files in all_filenames:\n",
    "    df = pd.read_csv(all_files,delimiter=';', na_values='NaN')\n",
    "    df['Tag'].iloc[0] , df['Tag'].iloc[-1] = ['INICIO_ARQ', 'FIM_ARQ']\n",
    "    frames.append(df)\n",
    "    \n",
    "combined_csv = pd.concat(frames)\n",
    "combined_csv.to_csv( \"combined_csv.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas dos arquivos concatenados: 967910\n"
     ]
    }
   ],
   "source": [
    "combined_csv.head() , combined_csv.tail()\n",
    "print(\"Número de linhas dos arquivos concatenados:\", len(combined_csv['Tag']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_csv.reset_index(inplace=True, drop=True)\n",
    "combined_csv = combined_csv.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>967900</th>\n",
       "      <td>Chefe</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967901</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967902</th>\n",
       "      <td>do</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967903</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967904</th>\n",
       "      <td>Plenário</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967905</th>\n",
       "      <td>\\n</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967906</th>\n",
       "      <td>id</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967907</th>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967908</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967909</th>\n",
       "      <td>20141203_ADI_4350_285683668</td>\n",
       "      <td>FIM_ARQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Token      Tag\n",
       "967900                        Chefe        O\n",
       "967901                                     O\n",
       "967902                           do        O\n",
       "967903                                     O\n",
       "967904                     Plenário        O\n",
       "967905                           \\n        O\n",
       "967906                           id        O\n",
       "967907                            :        O\n",
       "967908                                     O\n",
       "967909  20141203_ADI_4350_285683668  FIM_ARQ"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encontra parágrafo duplo no arquivo. Uma opção de separar por sentenças."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padrões(sentenças) encontrados: 9708\n"
     ]
    }
   ],
   "source": [
    "a_df = combined_csv #Simplifica o nome do arquivo \n",
    "starts = a_df[a_df['Token']=='\\n'].index & a_df[a_df['Token'].shift(-1)=='\\n'].index #Identifica os paragrafos duplos\n",
    "print(u'Padrões(sentenças) encontrados:', len(starts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_csv.iloc[:starts[0]+2] # Primeira sentença\n",
    "# combined_csv.iloc[starts[-1]+2:] # Última sentença"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 30s, sys: 82.4 ms, total: 5min 30s\n",
      "Wall time: 5min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     Token         Tag  Sentence #\n",
       " 0   Ementa  INICIO_ARQ  Sentence 1\n",
       " 1                    O  Sentence 1\n",
       " 2        e           O  Sentence 1\n",
       " 3                    O  Sentence 1\n",
       " 4  Acórdão           O  Sentence 1,\n",
       "                               Token      Tag     Sentence #\n",
       " 967905                           \\n        O  Sentence 9709\n",
       " 967906                           id        O  Sentence 9709\n",
       " 967907                            :        O  Sentence 9709\n",
       " 967908                                     O  Sentence 9709\n",
       " 967909  20141203_ADI_4350_285683668  FIM_ARQ  Sentence 9709)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "combined_csv['Sentence #'] = 'Sentence'\n",
    "\n",
    "combined_csv['Sentence #'][:starts[0]+2] = 'Sentence %d'%(1) # Primeira sentença\n",
    "combined_csv['Sentence #'][starts[-1]+2:] = 'Sentence %d'%(len(starts)+1) # Última sentença\n",
    "\n",
    "for i in range(1,len(starts)):\n",
    "    combined_csv['Sentence #'][starts[i-1]+2:starts[i]+2] = 'Sentence %d'%(i+1) \n",
    "\n",
    "combined_csv.head(), combined_csv.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9709"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_csv['Sentence #'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Sentence #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ementa</td>\n",
       "      <td>INICIO_ARQ</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acórdão</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token         Tag  Sentence #\n",
       "0   Ementa  INICIO_ARQ  Sentence 1\n",
       "1                    O  Sentence 1\n",
       "2        e           O  Sentence 1\n",
       "3                    O  Sentence 1\n",
       "4  Acórdão           O  Sentence 1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_csv.groupby('Tag').size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B_Doutrina',\n",
       " 'B_Doutrinador',\n",
       " 'B_Pessoa',\n",
       " 'B_Precedente',\n",
       " 'B_Ref. Legislativa',\n",
       " 'FIM_ARQ',\n",
       " 'INICIO_ARQ',\n",
       " 'I_Doutrina',\n",
       " 'I_Doutrinador',\n",
       " 'I_Pessoa',\n",
       " 'I_Precedente',\n",
       " 'I_Ref. Legislativa']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classes = np.unique(combined_csv.Tag.values).tolist()\n",
    "new_classes.remove('O')\n",
    "new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Sentence #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ementa</td>\n",
       "      <td>INICIO_ARQ</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acórdão</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token         Tag  Sentence #\n",
       "0   Ementa  INICIO_ARQ  Sentence 1\n",
       "1                    O  Sentence 1\n",
       "2        e           O  Sentence 1\n",
       "3                    O  Sentence 1\n",
       "4  Acórdão           O  Sentence 1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv['Token'] = combined_csv['Token'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa as frases para criar contexto na aprendizagem\n",
    "\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s['Token'].values.tolist(),\n",
    "                                                     s['Tag'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('Sentence #').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "getter = SentenceGetter(combined_csv)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "#     postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "#         postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "#         postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ementa', 'INICIO_ARQ'), (' ', 'O'), ('e', 'O'), (' ', 'O'), ('Acórdão', 'O'), (' ', 'O'), ('06/03/2018', 'O'), (' ', 'O'), ('PRIMEIRA', 'O'), (' ', 'O'), ('TURMA', 'O'), (' ', 'O'), ('\\n', 'O'), ('\\n', 'O')]\n"
     ]
    }
   ],
   "source": [
    "getter = SentenceGetter(combined_csv)\n",
    "\n",
    "sent = getter.get_next()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 248 ms, total: 1min 42s\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8184949279966993"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', #Gradient Descent\n",
    "    c1=0.1, # coefficient for L1 penalty\n",
    "    c2=0.1, # coefficient for L2 penalty\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True) # whether to include transitions that are possible, but not observed\n",
    "\n",
    "# crf = sklearn_crfsuite.CRF( # Performa 'pior'\n",
    "#     algorithm='l2sgd', # Stochastic Gradient Descent with L2 regularization term\n",
    "#     c2=0.1,\n",
    "#     max_iterations=100,\n",
    "#     all_possible_transitions=True) # whether to include transitions that are possible, but not observed\n",
    "\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=new_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        B_Doutrina      0.772     0.616     0.685        99\n",
      "     B_Doutrinador      0.696     0.448     0.545        87\n",
      "          B_Pessoa      0.698     0.636     0.665       807\n",
      "      B_Precedente      0.848     0.750     0.796       913\n",
      "B_Ref. Legislativa      0.817     0.715     0.763       892\n",
      "           FIM_ARQ      1.000     0.712     0.832        59\n",
      "        INICIO_ARQ      1.000     0.724     0.840        58\n",
      "        I_Doutrina      0.758     0.812     0.784      4225\n",
      "     I_Doutrinador      0.771     0.647     0.703      3565\n",
      "          I_Pessoa      0.839     0.763     0.799      4701\n",
      "      I_Precedente      0.881     0.836     0.858     13490\n",
      "I_Ref. Legislativa      0.869     0.827     0.847     12040\n",
      "\n",
      "         micro avg      0.844     0.796     0.819     40936\n",
      "         macro avg      0.829     0.707     0.760     40936\n",
      "      weighted avg      0.844     0.796     0.818     40936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(y_test, y_pred, labels = new_classes, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# Cria arquivo com todas as informações geradas pelo crf.\n",
    "\n",
    "crf.tagger_.dump(filename=\"crf_tagger.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olhando para a predição de cada X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('publique', 'O', 'O')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0][0]['word.lower()'], y_pred[0][0], y_test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria dataframe com o que o modelo predisse para análise.\n",
    "\n",
    "result = []\n",
    "for i in range(len(y_test)):\n",
    "    df = pd.DataFrame(zip([X_test[i][j]['word.lower()'] for j in range(len(X_test[i]))], y_test[i], y_pred[i]))\n",
    "#     df = pd.DataFrame(zip(X_test[i], y_test[i], y_pred[i]))\n",
    "    result.append(df)\n",
    "    \n",
    "result = pd.concat(result)\n",
    "result.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_csv = pd.concat(frames)\n",
    "result.to_csv(\"resultado.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325149, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_test</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>publique</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>se</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X_test y_test y_pred\n",
       "0  publique      O      O\n",
       "1         -      O      O\n",
       "2        se      O      O\n",
       "3         .      O      O\n",
       "4                O      O"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns = ['X_test','y_test', 'y_pred']\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_test</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>\\n</td>\n",
       "      <td>O</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>\\n</td>\n",
       "      <td>O</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>artigo</td>\n",
       "      <td>B_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td></td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>24</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>,</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td></td>\n",
       "      <td>B_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>incisos</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td></td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>ix;</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td></td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>xxi;</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td></td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>xxiv</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td></td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>e</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td></td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>xxvii</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td></td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>do</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td></td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>artigo</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td></td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>22</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>.</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>petição</td>\n",
       "      <td>B_Precedente</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>nº</td>\n",
       "      <td>I_Precedente</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>77.297</td>\n",
       "      <td>I_Precedente</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324504</th>\n",
       "      <td>§3º</td>\n",
       "      <td>O</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324505</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324506</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324507</th>\n",
       "      <td>da</td>\n",
       "      <td>O</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324508</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324509</th>\n",
       "      <td>constituição</td>\n",
       "      <td>O</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324510</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324511</th>\n",
       "      <td>da</td>\n",
       "      <td>O</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324512</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324513</th>\n",
       "      <td>república</td>\n",
       "      <td>O</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324514</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324528</th>\n",
       "      <td>petição</td>\n",
       "      <td>O</td>\n",
       "      <td>B_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324529</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324530</th>\n",
       "      <td>de</td>\n",
       "      <td>O</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324531</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324532</th>\n",
       "      <td>nº</td>\n",
       "      <td>O</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324533</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324534</th>\n",
       "      <td>78.714/2011</td>\n",
       "      <td>O</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324535</th>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "      <td>I_Precedente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324815</th>\n",
       "      <td></td>\n",
       "      <td>B_Pessoa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324816</th>\n",
       "      <td>ministro</td>\n",
       "      <td>I_Pessoa</td>\n",
       "      <td>B_Pessoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324889</th>\n",
       "      <td>“inclui</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324890</th>\n",
       "      <td></td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324891</th>\n",
       "      <td>§§</td>\n",
       "      <td>I_Ref. Legislativa</td>\n",
       "      <td>B_Ref. Legislativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324962</th>\n",
       "      <td>adc</td>\n",
       "      <td>B_Precedente</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324963</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324964</th>\n",
       "      <td>nº</td>\n",
       "      <td>I_Precedente</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324965</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324966</th>\n",
       "      <td>16</td>\n",
       "      <td>I_Precedente</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324967</th>\n",
       "      <td></td>\n",
       "      <td>I_Precedente</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12032 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              X_test              y_test              y_pred\n",
       "875               \\n                   O        I_Precedente\n",
       "876               \\n                   O        I_Precedente\n",
       "1632          artigo  B_Ref. Legislativa                   O\n",
       "1633                  I_Ref. Legislativa                   O\n",
       "1634              24  I_Ref. Legislativa                   O\n",
       "1635               ,  I_Ref. Legislativa                   O\n",
       "1648                  B_Ref. Legislativa                   O\n",
       "1649         incisos  I_Ref. Legislativa                   O\n",
       "1650                  I_Ref. Legislativa                   O\n",
       "1651             ix;  I_Ref. Legislativa                   O\n",
       "1652                  I_Ref. Legislativa                   O\n",
       "1653            xxi;  I_Ref. Legislativa                   O\n",
       "1654                  I_Ref. Legislativa                   O\n",
       "1655            xxiv  I_Ref. Legislativa                   O\n",
       "1656                  I_Ref. Legislativa                   O\n",
       "1657               e  I_Ref. Legislativa                   O\n",
       "1658                  I_Ref. Legislativa                   O\n",
       "1659           xxvii  I_Ref. Legislativa                   O\n",
       "1660                  I_Ref. Legislativa                   O\n",
       "1661              do  I_Ref. Legislativa                   O\n",
       "1662                  I_Ref. Legislativa                   O\n",
       "1663          artigo  I_Ref. Legislativa                   O\n",
       "1664                  I_Ref. Legislativa                   O\n",
       "1665              22  I_Ref. Legislativa                   O\n",
       "1666               .  I_Ref. Legislativa                   O\n",
       "1917         petição        B_Precedente                   O\n",
       "1918                        I_Precedente                   O\n",
       "1919              nº        I_Precedente                   O\n",
       "1920                        I_Precedente                   O\n",
       "1921          77.297        I_Precedente                   O\n",
       "...              ...                 ...                 ...\n",
       "324504           §3º                   O  I_Ref. Legislativa\n",
       "324505             ,                   O  I_Ref. Legislativa\n",
       "324506                                 O  I_Ref. Legislativa\n",
       "324507            da                   O  I_Ref. Legislativa\n",
       "324508                                 O  I_Ref. Legislativa\n",
       "324509  constituição                   O  I_Ref. Legislativa\n",
       "324510                                 O  I_Ref. Legislativa\n",
       "324511            da                   O  I_Ref. Legislativa\n",
       "324512                                 O  I_Ref. Legislativa\n",
       "324513     república                   O  I_Ref. Legislativa\n",
       "324514             ,                   O  I_Ref. Legislativa\n",
       "324528       petição                   O        B_Precedente\n",
       "324529                                 O        I_Precedente\n",
       "324530            de                   O        I_Precedente\n",
       "324531                                 O        I_Precedente\n",
       "324532            nº                   O        I_Precedente\n",
       "324533                                 O        I_Precedente\n",
       "324534   78.714/2011                   O        I_Precedente\n",
       "324535                                 O        I_Precedente\n",
       "324815                          B_Pessoa                   O\n",
       "324816      ministro            I_Pessoa            B_Pessoa\n",
       "324889       “inclui  I_Ref. Legislativa                   O\n",
       "324890                I_Ref. Legislativa                   O\n",
       "324891            §§  I_Ref. Legislativa  B_Ref. Legislativa\n",
       "324962           adc        B_Precedente                   O\n",
       "324963                      I_Precedente                   O\n",
       "324964            nº        I_Precedente                   O\n",
       "324965                      I_Precedente                   O\n",
       "324966            16        I_Precedente                   O\n",
       "324967                      I_Precedente                   O\n",
       "\n",
       "[12032 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result['y_test'] != result['y_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporção de erros: 0.03700457328793876\n"
     ]
    }
   ],
   "source": [
    "print('Proporção de erros:',result[result.y_test != result.y_pred].shape[0] / result.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erro apresentado devido a incapacidade de reconhecer a expressão regular dentro do arquivo '~/anaconda3/lib/python3.7/site-packages/pycrfsuite/_dumpparser.py'. \n",
    "\n",
    "Links para recorrer à ajuda: \n",
    "+ [https://github.com/TeamHG-Memex/eli5/issues/242]\n",
    "+ [https://github.com/scrapinghub/python-crfsuite/issues/14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-7f1b04d4fffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Top likely transitions:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint_transitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransition_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTop unlikely transitions:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn_crfsuite/estimator.py\u001b[0m in \u001b[0;36mtransition_features_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \"\"\"\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn_crfsuite/estimator.py\u001b[0m in \u001b[0;36m_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_cached\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_cached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagger_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.Tagger.info\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.Tagger.info\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pycrfsuite/_dumpparser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'parse_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_FILEHEADER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pycrfsuite/_dumpparser.py\u001b[0m in \u001b[0;36mparse_STATE_FEATURES\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_STATE_FEATURES\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\(\\d+\\) (.+) --> (.+) ([+-]?\\d+\\.\\d+)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "# Let’s check what classifier learned\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(5))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(y_test)\n",
    "y_test[0] + y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_novo = []\n",
    "for i in range(len(y_test)):\n",
    "    y_novo += y_test[i]\n",
    "y_novo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sctypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(y_test[i]) for i in range(len(y_test))])\n",
    "# len(y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "combined_csv.iloc[starts[i-1]+2:starts[i]+2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters\n",
    "\n",
    "•algorithm(str, optional (default='lbfgs'))  –  Training  algorithm.   Al-lowed values:–'lbfgs'- Gradient descent using the L-BFGS method–'l2sgd'- Stochastic Gradient Descent with L2 regularization term–'ap'- Averaged Perceptron–'pa'- Passive Aggressive (PA)–'arow'- Adaptive Regularization Of Weight Vector (AROW)\n",
    "\n",
    "•min_freq(float, optional (default=0)) – Cut-off threshold for occurrencefrequency of a feature.  CRFsuite will ignore features whose frequencies of occurrences inthe training data are no greater thanmin_freq. The default is no cut-off.\n",
    "\n",
    "•all_possible_states(bool, optional (default=False))    –    Specifywhether CRFsuite generates state features that do not even occur in the training data (i.e.,negative state features).  When True, CRFsuite generates state features that associate all ofpossible combinations between attributes and labels.Suppose that the numbers of attributes and labels are A and L respectively, this function willgenerate (A * L) features. Enabling this function may improve the labeling accuracy becausethe CRF model can learn the condition where an item is not predicted to its reference label.However, this function may also increase the number of features and slow down the trainingprocess drastically. This function is disabled by default.\n",
    "\n",
    "•all_possible_transitions(bool, optional (default=False)) – Spec-ify whether CRFsuite generates transition features that do not even occur in the training data(i.e., negative transition features).  When True, CRFsuite generates transition features thatassociate all of possible label pairs. Suppose that the number of labels in the training data isL, this function will generate (L * L) transition features. This function is disabled by default.\n",
    "\n",
    "•c1(float, optional (default=0)) – The coefficient for L1 regularization.  If anon-zero value is specified, CRFsuite switches to the Orthant-Wise Limited-memory Quasi-Newton (OWL-QN) method. The default value is zero (no L1 regularization).Supported training algorithms: lbfgs\n",
    "\n",
    "•c2(float, optional (default=1.0)) – The coefficient for L2 regularization.Supported training algorithms: l2sgd, lbfgs\n",
    "\n",
    "•max_iterations(int, optional (default=None)) – The maximum numberof iterations for optimization algorithms. Default value depends on training algorithm:–lbfgs - unlimited;–l2sgd - 1000;1.3.  API Reference13\n",
    "sklearn-crfsuite Documentation, Release 0.3–ap - 100;–pa - 100;–arow - 100.\n",
    "\n",
    "•num_memories(int, optional (default=6)) – The number of limited memo-ries for approximating the inverse hessian matrix.Supported training algorithms: lbfgs•epsilon(float, optional (default=1e-5)) – The epsilon parameter that de-termines the condition of convergence.Supported training algorithms: ap, arow, lbfgs, pa\n",
    "\n",
    "•period(int, optional (default=10)) – The duration of iterations to test thestopping criterion.Supported training algorithms: l2sgd, lbfgs\n",
    "\n",
    "•delta(float, optional (default=1e-5)) – The threshold for the stopping cri-terion; an iteration stops when the improvement of the log likelihood over the lastperioditerations is no greater than this threshold.Supported training algorithms: l2sgd, lbfgs\n",
    "\n",
    "•linesearch(str, optional (default='MoreThuente')) – The line searchalgorithm used in L-BFGS updates. Allowed values:–'MoreThuente'- More and Thuente’s method;–'Backtracking'- backtracking method with regular Wolfe condition;–'StrongBacktracking'- backtracking method with strong Wolfe condition.Supported training algorithms: lbfgs•max_linesearch(int, optional (default=20)) – The maximum number oftrials for the line search algorithm.Supported training algorithms: lbfgs\n",
    "\n",
    "•calibration_eta(float, optional (default=0.1)) – The initial value oflearning rate (eta) used for calibration.Supported training algorithms: l2sgd\n",
    "\n",
    "•calibration_rate(float, optional (default=2.0))  –  The  rate  of  in-crease/decrease of learning rate for calibration.Supported training algorithms: l2sgd\n",
    "\n",
    "•calibration_samples(int, optional (default=1000)) – The number ofinstances used for calibration. The calibration routine randomly chooses instances no largerthancalibration_samples.Supported training algorithms: l2sgd\n",
    "\n",
    "•calibration_candidates(int, optional (default=10))  –  The  numberof  candidates  of  learning  rate.   The  calibration  routine  terminates  after  findingcalibra-tion_samplescandidates of learning rates that can increase log-likelihood.Supported training algorithms: l2sgd14Chapter 1.  Contents\n",
    "sklearn-crfsuite Documentation, Release 0.3\n",
    "\n",
    "•calibration_max_trials(int, optional (default=20)) – The maximumnumber of trials of learning rates for calibration.  The calibration routine terminates aftertryingcalibration_max_trialscandidate values of learning rates.Supported training algorithms: l2sgd\n",
    "\n",
    "•pa_type(int, optional (default=1))  –  The  strategy  for  updating  featureweights. Allowed values:–0 - PA without slack variables;–1 - PA type I;–2 - PA type II.Supported training algorithms: pa\n",
    "\n",
    "•c(float, optional (default=1)) – Aggressiveness parameter (used only for PA-I and PA-II). This parameter controls the influence of the slack term on the objective func-tion.Supported training algorithms: pa\n",
    "\n",
    "•error_sensitive(bool, optional (default=True)) – If this parameter isTrue,  the optimization routine includes into the objective function the square root of thenumber of incorrect labels predicted by the model.Supported training algorithms: pa\n",
    "\n",
    "•averaging(bool, optional (default=True)) – If this parameter is True, theoptimization routine computes the average of feature weights at all updates in the trainingprocess (similarly to Averaged Perceptron).Supported training algorithms: pa\n",
    "\n",
    "•variance(float, optional (default=1)) – The initial variance of every fea-ture weight.  The algorithm initialize a vector of feature weights as a multivariate Gaussiandistribution with mean 0 and variancevariance.Supported training algorithms: arow\n",
    "\n",
    "•gamma(float, optional (default=1)) – The tradeoff between loss function andchanges of feature weights.Supported training algorithms: arow\n",
    "\n",
    "•verbose(bool, optional (default=False)) – Enable trainer verbose mode.\n",
    "\n",
    "•model_filename(str, optional (default=None))  –  A  path  to  an  existingCRFSuite model. This parameter allows to load and use existing crfsuite models.By  default,  model  files  are  created  automatically  and  saved  in  temporary  locations;  thepreferred way to save/load CRF models is to use pickle (or its alternatives like joblib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_csv.drop('Tag', axis=1) # Define o conjunto X\n",
    "v = DictVectorizer(sparse=True) # Função que transforma listas de features em vetores\n",
    "X = v.fit_transform(X.to_dict('records')) #Aplica a função de vetorização no conjunto \n",
    "                                          #X que foi colocado no formato 'records' (informa o que preenche cada coluna \n",
    "                                          # da linha i)\n",
    "y = combined_csv.Tag.values # Define o conjunto y\n",
    "\n",
    "classes = np.unique(y) # Define quais serão as classes baseado nos valores únicos da coluna y\n",
    "classes = classes.tolist() # Tranforma as classes de array para lista\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=0) # Divide o conjunto em treino\n",
    "                                                                                            #e teste\n",
    "X_train.shape, y_train.shape # Formato dos dados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
